{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自己编写的中文字符串切分、去停用词库(基于jieba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contact Me By Email: xinyaotian@yeah.net\n",
    "\n",
    "Or By Github : https://github.com/XinyaoTian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 导入TokChinese库中的TokChinese功能类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入库中的TokChinese类\n",
    "from TokChinese import TokChinese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getTokenizedList(string)\n",
    "* Input type : string\n",
    "* output type : list\n",
    "\n",
    "输入一个string,输出切分、去停用词后词语list[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['晚上', '吃', '披萨', '晚上', '吃', '披萨']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "tc = TokChinese()\n",
    "stringA = \"今天晚上我们去吃披萨吧！晚上吃披萨吧！\"\n",
    "\n",
    "# 使用getTokenizedList()\n",
    "word_list = tc.getTokenizedList(stringA)\n",
    "print(word_list)\n",
    "print(type(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getAndDedupTokenizedList(string)\n",
    "* Input type : string\n",
    "* output type : list\n",
    "\n",
    "输入一个string,输出切分、去停用词、去重后词语list[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['晚上', '吃', '披萨']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "tc = TokChinese()\n",
    "stringA = \"今天晚上我们去吃披萨吧！晚上吃披萨吧！\"\n",
    "\n",
    "# 使用 getAndDedupTokenizedList()\n",
    "word_list = tc.getAndDedupTokenizedList(stringA)\n",
    "print(word_list)\n",
    "print(type(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### getEnglishWordsList(string)\n",
    "* Input type : string\n",
    "* output type : list\n",
    "\n",
    "输入一个string,输出仅由“英文”构成的词语list[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good', 'morning']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "tc = TokChinese()\n",
    "stringA = \"Good morning!今天天气真不错。\"\n",
    "\n",
    "# 使用getEnglishWordsList()\n",
    "word_list = tc.getEnglishWordsList(stringA)\n",
    "print(word_list)\n",
    "print(type(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getTokenizedListAndAddToSelfList(string)\n",
    "* Input type : string\n",
    "* output type : list\n",
    "\n",
    "输入一个string,输出切分、去停用词后词语list[],并将这些切分好的词加入TokChinese类的一个list中\n",
    "\n",
    "#### countNumInSelfListWithDict()\n",
    "\n",
    "* output type : dict\n",
    "\n",
    "【!】 注意，使用这个函数之前需要先使用 getTokenizedListAndAddToSelfList() \n",
    "\n",
    "返回一个dict，以词语为key、出现次数为value。生成本dict的来源是TokChinese类中的一个私有变量list,\n",
    "\n",
    "使用getTokenizedListAndAddToSelfList(string)把词语添加进入TokChinese类中私有变量list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good', ' ', 'morning', '天天', '天气', '今天天气', '真不', '不错', '真不错', '昨天', '天气', '不错']\n",
      "<class 'list'>\n",
      "{'Good': 1, '真不错': 1, '天气': 2, ' ': 1, '今天天气': 1, '真不': 1, 'morning': 1, '不错': 2, '天天': 1, '昨天': 1}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "tc = TokChinese()\n",
    "stringA = \"Good morning!今天天气真不错。昨天的天气也很不错\"\n",
    "\n",
    "# 使用getTokenizedListAndAddToSelfList()\n",
    "word_list = tc.getTokenizedListAndAddToSelfList(stringA)\n",
    "print(word_list)\n",
    "print(type(word_list))\n",
    "\n",
    "# 在使用了 getTokenizedListAndAddToSelfList() 后，使用 countNumInSelfListWithDict() 统计词频\n",
    "count_dict = tc.countNumInSelfListWithDict()\n",
    "print(count_dict)\n",
    "print(type(count_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getSelfList()\n",
    "\n",
    "* output type : list\n",
    "返回一个存储在类中的list\n",
    "\n",
    "#### clearSelfList()\n",
    "\n",
    "* output type : list\n",
    "重置存储在类中的list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:['Good', ' ', 'morning', '天天', '天气', '今天天气', '真不', '不错', '真不错', '昨天', '天气', '不错']\n",
      "After cleaning:[]\n"
     ]
    }
   ],
   "source": [
    "tc = TokChinese()\n",
    "stringA = \"Good morning!今天天气真不错。昨天的天气也很不错\"\n",
    "\n",
    "# 切分string并将切分次加入类中的list\n",
    "word_list = tc.getTokenizedListAndAddToSelfList(stringA)\n",
    "\n",
    "# 查看类中的list\n",
    "selfList = tc.getSelfList()\n",
    "print(\"Before cleaning:\" + str(selfList))\n",
    "\n",
    "# 清空self.list\n",
    "tc.clearSelfList()\n",
    "\n",
    "# 再次查看类中的list\n",
    "selfList = tc.getSelfList()\n",
    "print(\"After cleaning:\" + str(selfList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 感谢您的使用\n",
    "#### The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
